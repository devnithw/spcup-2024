{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0x1-07Mk5vO",
        "outputId": "525432ce-e23c-435b-a775-6cf0faa84acc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_jW83sqTqrM",
        "outputId": "9017fc57-b3a3-4a4c-d897-d2c7b56eb9d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HvlGcTDzkZAO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "vt_2u_IBTmfh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "sZKkWIm_7yRW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BFGZ7BjRjCtO"
      },
      "outputs": [],
      "source": [
        "def extract_features(waveform, sample_rate):\n",
        "\n",
        "    \"\"\"Extract MFCC features from an audio file, shape=(TIME, MFCC).\"\"\"\n",
        "\n",
        "    # if len(waveform.shape) == 2:\n",
        "    #     waveform = librosa.to_mono(waveform.transpose())  No need since single channel\n",
        "\n",
        "    if sample_rate != 16000:\n",
        "        waveform = librosa.resample(waveform, sample_rate, 16000)\n",
        "\n",
        "    features = librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc= 20 )\n",
        "\n",
        "    return features.transpose()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, sample_rate = soundfile.read('/content/drive/MyDrive/ROBOVOX_SP_CUP_2024/data/single-channel/denoised_enrollments/spk_11-11_22_1_0_d1_ch5.wav')"
      ],
      "metadata": {
        "id": "jG4U3o1vlcQu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = extract_features(waveform, sample_rate)"
      ],
      "metadata": {
        "id": "-sPBoWr_l9Pl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB5b4siEl9O2",
        "outputId": "30b10047-9c16-4b62-bfad-2b2864290d04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(148, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "pou_SqDAnp-4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LstmSpeakerEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, embedding_size):\n",
        "\n",
        "        super(LstmSpeakerEncoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size,     # Number of MFCC coefficients\n",
        "            hidden_size,     # Number of hidden units in each LSTM layer\n",
        "            num_layers,    # Number of stacked LSTM layers (3)\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, embedding_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        embedding = self.fc(h_n[-1])  # Take the last hidden state as the embedding\n",
        "        return embedding"
      ],
      "metadata": {
        "id": "pI-1yKmonD7l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LstmSpeakerEncoder(20, hidden_size = 5, num_layers= 2, embedding_size =32)"
      ],
      "metadata": {
        "id": "fc8xzCN4v5f2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZU38EdwTyty",
        "outputId": "c7af7fb9-f0d8-4cf7-d2e8-e1b7cfcc3765"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "LstmSpeakerEncoder                       --\n",
              "├─LSTM: 1-1                              580\n",
              "├─Linear: 1-2                            192\n",
              "=================================================================\n",
              "Total params: 772\n",
              "Trainable params: 772\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anch_waveform, anch_sample_rate = soundfile.read('/content/drive/MyDrive/ROBOVOX_SP_CUP_2024/data/single-channel/denoised_enrollments/spk_2-2_1_1_0_d5_ch5.wav')\n",
        "anch_f = extract_features(anch_waveform,anch_sample_rate)\n",
        "anchor_input = torch.tensor(anch_f, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "pos_waveform, pos_sample_rate = soundfile.read('/content/drive/MyDrive/ROBOVOX_SP_CUP_2024/data/single-channel/denoised_enrollments/spk_2-2_1_1_0_d6_ch5.wav')\n",
        "pos_f = extract_features(pos_waveform, pos_sample_rate)\n",
        "pos_input = torch.tensor(pos_f, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "neg_waveform, neg_sample_rate = soundfile.read('/content/drive/MyDrive/ROBOVOX_SP_CUP_2024/data/single-channel/denoised_enrollments/spk_3-3_22_0_0_d2_ch5.wav')\n",
        "neg_f = extract_features(neg_waveform, neg_sample_rate)\n",
        "neg_input = torch.tensor(neg_f, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n"
      ],
      "metadata": {
        "id": "IBkHfeO3wRwI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor_embedding = model(anchor_input)\n",
        "positive_embedding = model(pos_input)\n",
        "negative_embedding = model(neg_input)"
      ],
      "metadata": {
        "id": "yb-nZLaRxOiO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_positive = torch.norm(anchor_embedding - positive_embedding, p=2, dim=1)\n",
        "distance_positive.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMzh9wwgR3Rn",
        "outputId": "1c8acb34-80d2-49fd-fb7d-6a0bc2e5387a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6429540514945984"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n"
      ],
      "metadata": {
        "id": "6jYjWmjI1LD0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT3rh4JK18bN",
        "outputId": "2125e0e0-a4e2-4889-b608-35e90c9a70e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8674868941307068"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, folder_path):\n",
        "        self.folder_path = folder_path\n",
        "        self.files = sorted(os.listdir(folder_path))\n",
        "        self.data = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        data = []\n",
        "        for recordings in self.files:\n",
        "            path = os.path.join(self.folder_path, recordings)\n",
        "\n",
        "            waveform, sample_rate = soundfile.read(path)\n",
        "            label = recordings.split('-')[0]\n",
        "            data.append((extract_features(waveform, sample_rate), label))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        anchor = self.data[index]\n",
        "\n",
        "        # Sample positive from the same class\n",
        "        positive_class_samples = [i for i,(features,label) in enumerate(self.data) if label == anchor[1]]\n",
        "        positive_index = np.random.choice(positive_class_samples)\n",
        "\n",
        "        # Sample negative from a different class\n",
        "        negative_class_samples = [i for i,(features,label) in enumerate(self.data) if label != anchor[1]]\n",
        "        negative_index = np.random.choice(negative_class_samples)\n",
        "\n",
        "        return index, positive_index, negative_index"
      ],
      "metadata": {
        "id": "mZMTQCkL7tAE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TripletDataset('/content/drive/MyDrive/ROBOVOX_SP_CUP_2024/data/single-channel/denoised_enrollments')"
      ],
      "metadata": {
        "id": "zUlz7G7J79VG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_store = dataset.data"
      ],
      "metadata": {
        "id": "IgzT_-w-GYN9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hP8s0mB8I-t",
        "outputId": "fef2f188-ba23-4efb-f05d-24c8c5cbfaa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "225"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 25  #Note that I am not using powers of 2\n",
        "triplet_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "LS23-XmcBpSF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(triplet_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC0Dm4dZF1xk",
        "outputId": "24218906-d148-44dc-ba3e-5996169b149a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "model = LstmSpeakerEncoder(20, hidden_size = 10, num_layers= 5, embedding_size =32)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Epoch %d running...\"%(epoch))\n",
        "\n",
        "  model.train()\n",
        "  correct = 0\n",
        "  train_loss = 0\n",
        "  optimizer.zero_grad()\n",
        "  total = 0\n",
        "\n",
        "  for k in triplet_loader:\n",
        "    loss = 0\n",
        "    for b in range(k[0].shape[0]):  #iterate through each in batch - NOT EFFICIET AND I KNOW IT\n",
        "\n",
        "      anc = data_store[k[0][b]][0]\n",
        "      pos = data_store[k[1][b]][0]\n",
        "      neg = data_store[k[2][b]][0]\n",
        "      # print(anc.shape)\n",
        "      # print(pos.shape)\n",
        "      # print(neg.shape)\n",
        "\n",
        "      anchor_input = torch.tensor(anc, dtype=torch.float32).unsqueeze(0)\n",
        "      pos_input = torch.tensor(pos, dtype=torch.float32).unsqueeze(0)\n",
        "      neg_input = torch.tensor(neg, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "      anchor_embedding = model(anchor_input)\n",
        "      positive_embedding = model(pos_input)\n",
        "      negative_embedding = model(neg_input)\n",
        "\n",
        "      loss += triplet_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
        "\n",
        "      distance_positive =  torch.norm(anchor_embedding - positive_embedding, p=2, dim=1)\n",
        "      distance_negative = torch.norm(anchor_embedding - negative_embedding, p=2, dim=1)\n",
        "\n",
        "      # Check if distances satisfy triplet condition\n",
        "      if distance_positive < distance_negative:\n",
        "        correct += 1\n",
        "\n",
        "      total += 1\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "\n",
        "\n",
        "  print('Accuracy: ',(correct/total)*100, '   train loss: ',train_loss)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jefcpf15C-wt",
        "outputId": "06703134-27fd-46e1-9e36-6824b8009d17"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 running...\n",
            "Accuracy:  65.77777777777779    train loss:  224.92675018310547\n",
            "Epoch 1 running...\n",
            "Accuracy:  73.77777777777777    train loss:  224.91765785217285\n",
            "Epoch 2 running...\n",
            "Accuracy:  68.0    train loss:  224.8962745666504\n",
            "Epoch 3 running...\n",
            "Accuracy:  72.44444444444444    train loss:  224.93536186218262\n",
            "Epoch 4 running...\n",
            "Accuracy:  65.77777777777779    train loss:  224.92816925048828\n",
            "Epoch 5 running...\n",
            "Accuracy:  61.33333333333333    train loss:  224.94325256347656\n",
            "Epoch 6 running...\n",
            "Accuracy:  68.44444444444444    train loss:  224.90753364562988\n",
            "Epoch 7 running...\n",
            "Accuracy:  69.33333333333334    train loss:  224.8996067047119\n",
            "Epoch 8 running...\n",
            "Accuracy:  70.22222222222221    train loss:  224.90123176574707\n",
            "Epoch 9 running...\n",
            "Accuracy:  66.66666666666666    train loss:  224.8723087310791\n"
          ]
        }
      ]
    }
  ]
}