{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VjQ2ZinD637e"},"outputs":[],"source":["# 3. Add required transform for training files\n","# 4. Use transfer learn for model\n","# 5. Inference on test files"]},{"cell_type":"markdown","metadata":{"id":"TgyBYACK7MX9"},"source":["# 1. Download dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"elapsed":9477,"status":"ok","timestamp":1706926175014,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"},"user_tz":-330},"id":"T2a1ohmh60hQ","outputId":"83ef1dd6-7117-4c7c-d1f7-97b1ca7cb0a6"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1S9lZmbaPyGohZ6INfTHhcmOxD9r4DQrR\n","From (redirected): https://drive.google.com/uc?id=1S9lZmbaPyGohZ6INfTHhcmOxD9r4DQrR&confirm=t&uuid=199f3d31-04c0-4c6b-b488-271c70513c54\n","To: /content/denoised_dataset.zip\n","100%|██████████| 675M/675M [00:08<00:00, 81.1MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/denoised_dataset.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["# TODO: Get dataset\n","import gdown\n","\n","url = 'https://drive.google.com/uc?id=1S9lZmbaPyGohZ6INfTHhcmOxD9r4DQrR'\n","output = '/content/denoised_dataset.zip'\n","\n","gdown.download(url, output, quiet=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpTvjnSF7UNw"},"outputs":[],"source":["# TODO : Extract denoised dataset\n","\n","!unzip -q \"/content/denoised_dataset.zip\" -d \"/content/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1706926198387,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"},"user_tz":-330},"id":"aMjsH-i97aNX","outputId":"c68b1583-aa62-4b15-f34c-ea1bd810eb86"},"outputs":[{"output_type":"stream","name":"stdout","text":["denoised_dataset.zip  denoised_enrollments  denoised_test  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1VuF2Zu7XiL"},"outputs":[],"source":["train_path = \"/content/denoised_enrollments\"\n","test_path = \"/content/denoised_test\"\n","trials_file_path = \"/content/drive/MyDrive/signle-channel-trials.txt\"\n","\n","# Pretrained model weights\n","model_path = \"/content/drive/MyDrive/Sasika/xvector_weights.pth\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25262,"status":"ok","timestamp":1706926223642,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"},"user_tz":-330},"id":"5gRedFre6wKk","outputId":"f05e67fe-0d79-4655-8970-848f18afc0e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# prompt: mount drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"komBQmnh73mg"},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gA-lq8qW6tDw"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class TDNN(nn.Module):\n","    def __init__(self, context_size, dilation, in_dim, out_dim):\n","        super(TDNN, self).__init__()\n","\n","        self.context_size = context_size\n","        self.dilation = dilation\n","        self.in_dim = in_dim\n","        self.out_dim = out_dim\n","        self.layer_context_size = context_size * dilation - dilation + 1\n","        self._input_x_output = f\"{in_dim * context_size} x {out_dim}\"\n","\n","        self.kernel = nn.Linear(in_dim * context_size, out_dim)\n","        self.nonlinearity = nn.ReLU()\n","\n","    def forward(self, x):\n","        assert len(x.shape) == 3\n","        B, T, D = x.shape\n","        assert (\n","            D == self.in_dim\n","        ), f\"[error] Expected input dimension is {self.in_dim}, not {D}.\"\n","\n","        x = x.unsqueeze(1)\n","\n","        # Unfold input into smaller temporal contexts\n","        x = F.unfold(\n","            x,\n","            (self.context_size, self.in_dim),\n","            stride=(1, self.in_dim),\n","            dilation=(self.dilation, 1),\n","        )\n","\n","        # x.shape: (N, output_dim*context_size, new_t)\n","        x = x.transpose(1, 2)\n","        x = self.kernel(x.float())\n","        x = self.nonlinearity(x)\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CEl3AtQW6tDy"},"outputs":[],"source":["################################################### Original Code\n","from pathlib import Path\n","import torch\n","import torch.nn as nn\n","# from .tdnn import TDNN\n","# from xvector_jtubespeech.network.tdnn import TDNN\n","\n","\n","# Don't use the following name (Xvector)\n","def XVector(model_path=\"xvectors_weights.pth\"):\n","    model_not_exist_msg = (\n","        f\"[error] dumped file of model's state dict does not exist at {model_path}\"\n","    )\n","    assert Path(model_path).exists(), model_not_exist_msg\n","\n","    model = _XVector(24, 1233)\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    return model\n","\n","\n","class _XVector(nn.Module):\n","    def __init__(self, in_dim, classes, stat_dim=1500, hidden_dim=512):\n","        super(_XVector, self).__init__()\n","\n","        self.stat_dim = stat_dim\n","        self.hidden_dim = hidden_dim\n","\n","        # from Table 1. of the X-Vectors paper:\n","        # https://www.danielpovey.com/files/2018_icassp_xvectors.pdf\n","        self.frames = nn.Sequential(\n","            TDNN(5, 1, in_dim, hidden_dim),\n","            TDNN(3, 2, hidden_dim, hidden_dim),\n","            TDNN(3, 3, hidden_dim, hidden_dim),\n","            TDNN(1, 1, hidden_dim, hidden_dim),\n","            TDNN(1, 1, hidden_dim, stat_dim),\n","        )\n","        self.segment_6 = nn.Linear(stat_dim * 2, hidden_dim)\n","        self.segment_7 = nn.Linear(hidden_dim, hidden_dim)\n","        self.output = nn.Linear(hidden_dim, classes)\n","\n","    def vectorize(self, x):\n","        x = self.frames(x)\n","\n","        # stats-pooling\n","        mean = torch.mean(x, 1)\n","        std = torch.std(x, 1)\n","        x = torch.cat((mean, std), 1)\n","\n","        vec = self.segment_6(x)\n","\n","        return vec\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ov0cJDr66tD0"},"outputs":[],"source":["# The architecture for my implementation\n","class _Xvector(nn.Module):\n","    def __init__(self, in_dim, classes, stat_dim=1500, hidden_dim=512):\n","        super(_XVector, self).__init__()\n","\n","        self.stat_dim = stat_dim\n","        self.hidden_dim = hidden_dim\n","\n","        # from Table 1. of the X-Vectors paper:\n","        # https://www.danielpovey.com/files/2018_icassp_xvectors.pdf\n","        self.frames = nn.Sequential(\n","            TDNN(5, 1, in_dim, hidden_dim),\n","            TDNN(3, 2, hidden_dim, hidden_dim),\n","            TDNN(3, 3, hidden_dim, hidden_dim),\n","            TDNN(1, 1, hidden_dim, hidden_dim),\n","            TDNN(1, 1, hidden_dim, stat_dim),\n","        )\n","        self.segment_6 = nn.Linear(stat_dim * 2, hidden_dim)\n","        self.segment_7 = nn.Linear(hidden_dim, hidden_dim)\n","        self.output = nn.Linear(hidden_dim, classes)\n","\n","    def vectorize(self, x):\n","        x = self.frames(x)\n","\n","        # stats-pooling\n","        mean = torch.mean(x, 1)\n","        std = torch.std(x, 1)\n","        x = torch.cat((mean, std), 1)\n","\n","        vec = self.segment_6(x)\n","\n","        return vec"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using\",device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zf9vPrisvCWT","executionInfo":{"status":"ok","timestamp":1706926399373,"user_tz":-330,"elapsed":5,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"}},"outputId":"d1c04874-b1f7-444e-b4bc-cebc74e7abf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LYzAt7t8ajG","executionInfo":{"status":"ok","timestamp":1706926437531,"user_tz":-330,"elapsed":5,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"}},"outputId":"967f7618-43b9-450b-de05-1a3512928fae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":13}],"source":["# Load the pretrained model\n","model = _XVector(24, 1233)\n","model.load_state_dict(torch.load(model_path,map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJPhjECt6tD1","executionInfo":{"status":"ok","timestamp":1706926460876,"user_tz":-330,"elapsed":402,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"}},"outputId":"04c59af2-c631-4b54-a48c-05a2baa0055d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config',\n"," 'drive',\n"," 'denoised_test',\n"," 'denoised_dataset.zip',\n"," 'denoised_enrollments',\n"," 'sample_data']"]},"metadata":{},"execution_count":14}],"source":["import os\n","os.listdir()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZpX4tMM6tD2"},"outputs":[],"source":["model.state_dict();"]},{"cell_type":"markdown","metadata":{"id":"o11QlBEP6tD2"},"source":["### Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KO7I2Gaf-nD8"},"outputs":[],"source":["model;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTPhiCne6tD4"},"outputs":[],"source":["class TransferLearningModel(nn.Module):\n","    def __init__(self, pre_trained_model, classes, stat_dim=1500, hidden_dim=512):\n","        super(TransferLearningModel, self).__init__()\n","\n","        # Use the pre-trained model until the last layer\n","        self.pre_trained_model = pre_trained_model\n","\n","        # Modify the output layer to match the number of classes in the French dataset\n","        self.pre_trained_model.output = nn.Linear(pre_trained_model.hidden_dim, classes)\n","\n","    def forward(self, x):\n","        # Forward pass through the modified model\n","        x = self.pre_trained_model(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xA7TR3nq9syX"},"outputs":[],"source":["num_speakers = 75\n","num_epochs = 40\n","batch_size = 32"]},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import Dataset\n","from scipy.io import wavfile\n","import torch.nn.functional as F\n","import numpy as np\n","from torchaudio.compliance import kaldi\n","\n","max_len = 2000\n","\n","# Define your custom dataset class\n","class AudioDataset(Dataset):\n","    def __init__(self, root_dir):\n","        self.root_dir = root_dir\n","        self.file_list = os.listdir(root_dir)\n","        self.transform = None\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, idx):\n","        file_name = self.file_list[idx]\n","        # Construct the full path to the file\n","        file_path = os.path.join(self.root_dir, file_name)\n","\n","        speaker_label = file_name.split(\"-\")[0]\n","\n","        sample_rate, waveform = wavfile.read(file_path)\n","\n","        waveform = torch.from_numpy(waveform.astype(np.float32)).unsqueeze(0)\n","\n","        # Check if CUDA is available and move data to GPU\n","        waveform = waveform.to(device)\n","\n","        # Apply preprocessing (MFCC extraction)\n","        mfcc = kaldi.mfcc(waveform, num_ceps=24, num_mel_bins=24)  # [1, T, 24]\n","        mfcc = mfcc.unsqueeze(0)\n","\n","        # Apply any additional transformations if needed\n","        if self.transform:\n","            mfcc = self.transform(mfcc)\n","\n","        # Get the dynamic time dimension T\n","        T = mfcc.size(1)\n","\n","        # Pad or truncate the time dimension to a fixed length (max_len)\n","        if T < max_len:\n","            # If T is less than max_len, pad with zeros\n","            padding = (0, max_len - T)\n","            mfcc_padded = F.pad(mfcc, padding, 'constant', 0)\n","\n","        elif T > max_len:\n","            # If T is greater than max_len, truncate\n","            mfcc_padded = mfcc[:, :max_len, :]\n","\n","        print(mfcc_padded.shape)\n","\n","        return mfcc_padded, speaker_label\n"],"metadata":{"id":"WTVqb2QN_4u2","executionInfo":{"status":"ok","timestamp":1706930769687,"user_tz":-330,"elapsed":5,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["# Instantiate your _XVector model -----------------------------------------------------------\n","in_dim = 1  # Assuming mono audio\n","classes = 75  # Set the number of classes accordingly\n","model = _XVector(in_dim, classes)\n","\n","# Instantiate your custom dataset\n","dataset = AudioDataset(root_dir='/content/denoised_enrollments/')\n","\n","# Set your batch size and other training parameters\n","batch_size = 32\n","num_epochs = 10\n","learning_rate = 0.001\n","\n","# Create a DataLoader -----------------------------------------------------------------------\n","data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","# Training -----------------------------------------------------------------------------------\n","for epoch in range(num_epochs):\n","    for batch_idx, (mfcc, speaker_label) in enumerate(data_loader):\n","        mfcc, speaker_label = mfcc.to(device), speaker_label.to(device)\n","\n","        # Forward pass\n","        outputs = model(mfcc)\n","\n","        # Compute the loss\n","        loss = criterion(outputs, speaker_label)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(data_loader)}], Loss: {loss.item()}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":985},"id":"AnlXUVWm44HG","executionInfo":{"status":"error","timestamp":1706930772234,"user_tz":-330,"elapsed":676,"user":{"displayName":"sasika SPCUP","userId":"10995634079336280829"}},"outputId":"e77ffc38-f4d2-4064-b63c-d5e87751b317"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1188, 836])\n","torch.Size([1, 318, 1706])\n","torch.Size([1, 327, 1697])\n","torch.Size([1, 591, 1433])\n","torch.Size([1, 1304, 720])\n","torch.Size([1, 324, 1700])\n","torch.Size([1, 362, 1662])\n","torch.Size([1, 1688, 336])\n","torch.Size([1, 383, 1641])\n","torch.Size([1, 326, 1698])\n","torch.Size([1, 1082, 942])\n","torch.Size([1, 1198, 826])\n","torch.Size([1, 319, 1705])\n","torch.Size([1, 345, 1679])\n","torch.Size([1, 330, 1694])\n","torch.Size([1, 315, 1709])\n","torch.Size([1, 1044, 980])\n","torch.Size([1, 413, 1611])\n","torch.Size([1, 368, 1656])\n","torch.Size([1, 341, 1683])\n","torch.Size([1, 1590, 434])\n","torch.Size([1, 373, 1651])\n","torch.Size([1, 367, 1657])\n","torch.Size([1, 1241, 783])\n","torch.Size([1, 380, 1644])\n","torch.Size([1, 401, 1623])\n","torch.Size([1, 1283, 741])\n","torch.Size([1, 1417, 607])\n","torch.Size([1, 371, 1653])\n","torch.Size([1, 575, 1449])\n","torch.Size([1, 451, 1573])\n","torch.Size([1, 1240, 784])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"stack expects each tensor to be equal size, but got [1, 1188, 836] at entry 0 and [1, 318, 1706] at entry 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-28f69e016282>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Training -----------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mmfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 1188, 836] at entry 0 and [1, 318, 1706] at entry 1"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}